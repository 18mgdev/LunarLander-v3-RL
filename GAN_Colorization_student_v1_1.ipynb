{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a1sYUGFWerc"
      },
      "source": [
        "# Practical Assesment Task #1: Colorizing Images with Generative Adversarial Networks\n",
        "Técnicas Generativas y Aprendizaje por Refuerzo - Curso 2024/2025\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IhOeNWcWere"
      },
      "source": [
        "## Import Dependencies and Set General Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KWdWy3g4Werf",
        "outputId": "b3bbf38d-5559-4ab9-eb6b-cd5cd813b243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow -q\n",
        "%pip install scikit-image -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K6upeodWWerg"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Enable memory growth for GPU\u001b[39;00m\n\u001b[0;32m     21\u001b[0m physical_devices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(\u001b[43mphysical_devices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Constants\u001b[39;00m\n\u001b[0;32m     25\u001b[0m IMAGE_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.layers import (\n",
        "    Activation, AveragePooling2D, BatchNormalization, Conv2D, Dense,\n",
        "    Dropout, Flatten, LeakyReLU, UpSampling2D)\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from time import time\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Enable memory growth for GPU\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# Constants\n",
        "IMAGE_SIZE = 32\n",
        "EPOCHS = 200 # Increase or decrease as appropriate\n",
        "BATCH_SIZE = 128\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "WORKDIR = \"/content/drive/My Drive/Colab Notebooks/Workspace/\"\n",
        "\n",
        "# Create directories\n",
        "Path(WORKDIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(f\"{WORKDIR}/results\").mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dgKZtrCWerg"
      },
      "source": [
        "## Define Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vZ3ryPLAWerg"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(images, debug=False):\n",
        "    \"\"\"\n",
        "    This function converts a list of RGB images to the LAB color space, and separates the L channel from the A and B channels.\n",
        "    The images are normalized and reshaped to the appropriate dimensions for the model.\n",
        "\n",
        "    Parameters:\n",
        "    images (list): A list of RGB images\n",
        "    debug (bool): If True, the function will display the original and converted images\n",
        "\n",
        "    Returns:\n",
        "    X (np.array): A numpy array of L channels of the images\n",
        "    Y (np.array): A numpy array of A and B channels of the images\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in images:\n",
        "        lab_image_array = rgb2lab(i / 255)  # Convert the image from RGB to LAB color space\n",
        "        x = lab_image_array[:, :, 0]  # Get the L channel\n",
        "        y = lab_image_array[:, :, 1:]  # Get the A and B channels\n",
        "        y /= 128  # normalize\n",
        "\n",
        "        if debug:  # If debug is True, display the original and converted images\n",
        "            fig = plt.figure()\n",
        "            fig.add_subplot(1, 2, 1)\n",
        "            plt.imshow(i / 255)\n",
        "\n",
        "            fig.add_subplot(1, 2, 2)\n",
        "            plt.imshow(lab2rgb(np.dstack((x, y * 128))))\n",
        "            plt.show()\n",
        "\n",
        "        X.append(x.reshape(IMAGE_SIZE, IMAGE_SIZE, 1))  # Reshape the L channel and append to the list\n",
        "        Y.append(y)  # Append the A and B channels to the list\n",
        "\n",
        "    X = np.array(X, dtype=np.float32)  # Convert the list to a numpy array\n",
        "    Y = np.array(Y, dtype=np.float32)  # Convert the list to a numpy array\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def load_data(force=False):\n",
        "    \"\"\"\n",
        "    This function loads the CIFAR-10 dataset, processes it, and saves/loads the processed data to/from the disk.\n",
        "\n",
        "    Parameters:\n",
        "    force (bool): If True, the function will reprocess the data even if it already exists on the disk\n",
        "\n",
        "    Returns:\n",
        "    X_train, Y_train, X_test, Y_test (np.array): Numpy arrays of the training and testing data\n",
        "    \"\"\"\n",
        "    is_saved_arrays_exist = os.path.isfile(os.path.join(WORKDIR, 'X_train.npy'))  # Check if the processed data already exists on the disk\n",
        "\n",
        "    if not is_saved_arrays_exist or force:  # If the processed data does not exist or if force is True, process the data\n",
        "        (train_images, _), (test_images, _) = cifar10.load_data()  # Load the CIFAR-10 dataset\n",
        "        X_train, Y_train = generate_dataset(train_images)  # Process the training images\n",
        "        X_test, Y_test = generate_dataset(test_images)  # Process the testing images\n",
        "        print('Saving processed data to Drive')\n",
        "        np.save(os.path.join(WORKDIR, 'X_train.npy'), X_train)  # Save the processed training data to the disk\n",
        "        np.save(os.path.join(WORKDIR, 'Y_train.npy'), Y_train)  # Save the processed training data to the disk\n",
        "        np.save(os.path.join(WORKDIR, 'X_test.npy'), X_test)  # Save the processed testing data to the disk\n",
        "        np.save(os.path.join(WORKDIR, 'Y_test.npy'), Y_test)  # Save the processed testing data to the disk\n",
        "    else:  # If the processed data exists and force is False, load the data from the disk\n",
        "        print('Loading processed data from Drive')\n",
        "        X_train = np.load(os.path.join(WORKDIR, 'X_train.npy'))  # Load the processed training data from the disk\n",
        "        Y_train = np.load(os.path.join(WORKDIR, 'Y_train.npy'))  # Load the processed training data from the disk\n",
        "        X_test = np.load(os.path.join(WORKDIR, 'X_test.npy'))  # Load the processed testing data from the disk\n",
        "        Y_test = np.load(os.path.join(WORKDIR, 'Y_test.npy'))  # Load the processed testing data from the disk\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS17nTCfWerh"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kipEafQxWerh",
        "outputId": "ce7fe79b-89b3-4300-d59f-5c1e8fc14c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Saving processed data to Drive\n"
          ]
        }
      ],
      "source": [
        "# Load the processed training and testing data\n",
        "X_train, Y_train, X_test, Y_test = load_data()\n",
        "\n",
        "# Create TensorFlow datasets from the training and testing data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "# Shuffle the training dataset and batch both datasets\n",
        "# SHUFFLE_BUFFER_SIZE determines the randomness of the shuffling\n",
        "# BATCH_SIZE determines the number of samples that will be propagated through the network at once\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_arfNdPUWerh"
      },
      "source": [
        "## Define Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m_sP9HjyWeri"
      },
      "outputs": [],
      "source": [
        "def build_generator_model():\n",
        "    \"\"\"\n",
        "    This function builds the generator model for the GAN. The generator is responsible for generating new, fake images.\n",
        "    It uses a series of Conv2D, BatchNormalization, and UpSampling2D layers.\n",
        "\n",
        "    Returns:\n",
        "    model (Sequential): The generator model\n",
        "    \"\"\"\n",
        "    model = Sequential()  # Initialize the model\n",
        "\n",
        "    # Downsampling (Extracción de características)\n",
        "    model.add(Conv2D(64, (3,3), strides=2, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2D(128, (3,3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2D(256, (3,3), strides=2, padding='same'))  # Ahora 4x4\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    # Upsampling (Reconstrucción)\n",
        "    model.add(UpSampling2D(size=(2,2)))  # 4x4 → 8x8\n",
        "    model.add(Conv2D(128, (3,3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(UpSampling2D(size=(2,2)))  # 8x8 → 16x16\n",
        "    model.add(Conv2D(64, (3,3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(UpSampling2D(size=(2,2)))  # 16x16 → 32x32\n",
        "    model.add(Conv2D(32, (3,3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(Conv2D(2, (3,3), padding='same'))  # Salida con canales A y B\n",
        "    model.add(Activation('tanh'))  # Salida en [-1,1]\n",
        "\n",
        "\n",
        "    # COMPLETE\n",
        "\n",
        "    # Suggested architecture:\n",
        "    # Downsampling\n",
        "        # Add a series of Conv2D layers followed by BatchNormalization layers\n",
        "        # Conv2D layers are used for the convolution operation that extracts features from the input images\n",
        "        # Conv2D layers with stride=1 preserve the dimensions of the image\n",
        "        # Conv2D layers with stride=2 downsample the image (i.e., reduce the dimensions of the image by half)\n",
        "        # BatchNormalization layers are used to normalize the activations of the previous layer at each batch\n",
        "        # ReLU activation function is used to add non-linearity to the output of the previous layer\n",
        "        # Padding is set to 'same' to preserve the dimensions of the image\n",
        "        # Repeat this series of layers N times\n",
        "\n",
        "    # Upsampling\n",
        "        # UpSampling2D layer is used to increase the dimension of the image\n",
        "        # Add as many UpSampling2D layers as Conv2D layers with stride=2 to upsample the image to its original dimensions\n",
        "        # Add a series of Conv2D layers followed by BatchNormalization layers\n",
        "        # BatchNormalization layers are used to normalize the activations of the previous layer at each batch\n",
        "        # ReLU activation function is used to add non-linearity to the output of the previous layer\n",
        "\n",
        "    # Output layer\n",
        "        # Add a Conv2D layer with 2 filters to output the A and B LAB channels of the image\n",
        "        # Activation layer is used to apply the tanh activation function to the output\n",
        "        # tanh activation function is used because the pixels of the output images range from -1 to 1\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HaWa2yxWeri"
      },
      "source": [
        "## Define Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E6iQBr6LWeri"
      },
      "outputs": [],
      "source": [
        "def build_discriminator_model():\n",
        "    \"\"\"\n",
        "    This function builds the discriminator model for the GAN. The discriminator is responsible for distinguishing real images from fake ones.\n",
        "    It is recommended to use a series of Conv2D, Dropout, AveragePooling2D, Flatten, Dense, LeakyReLU, BatchNormalization, and Activation layers to create the model.\n",
        "\n",
        "    Returns:\n",
        "    model (Sequential): The discriminator model\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()  # Initialize the model\n",
        "\n",
        "    # Bloques de convolución\n",
        "    model.add(Conv2D(64, (3,3), strides=2, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 2)))  # Canales A y B en LAB\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(128, (3,3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(256, (3,3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Pooling y capas densas\n",
        "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Salida en [0,1] (real o falsa)\n",
        "    # COMPLETE\n",
        "\n",
        "    # Suggested architecture:\n",
        "    # Convolution blocks\n",
        "        # Add a series of Conv2D layers followed by Dropout\n",
        "        # Conv2D layers are used for the convolution operation that extracts features from the input images\n",
        "        # Dropout layers are used to prevent overfitting by randomly setting a fraction rate of input units to 0 at each update during training time\n",
        "        # Repeat this series of layers N times\n",
        "\n",
        "    # Pooling and dense layers\n",
        "        # AveragePooling2D layer is used to downscale the image spatially\n",
        "        # Flatten layer is used to convert the 2D matrix of features into a vector that can be fed into a fully connected neural network classifier\n",
        "        # Dense layers are the regular deeply connected neural network layers\n",
        "        # LeakyReLU is a type of activation function that allows a small gradient when the unit is not active\n",
        "        # BatchNormalization layers are used to normalize the activations of the previous layer at each batch\n",
        "        # Dropout layers are used to prevent overfitting by randomly setting a fraction rate of input units to 0 at each update during training time\n",
        "\n",
        "    # Output layer\n",
        "        # Add a Dense layer with 1 unit to output the probability of the input image being real or synthetic\n",
        "        # Activation layer is used to apply the sigmoid activation function to the output\n",
        "        # sigmoid activation function is used because the output is a probability between 0 and 1\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsF16XfFWeri"
      },
      "source": [
        "## Define Generator and Discriminator Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XeCpaLMcWerj"
      },
      "outputs": [],
      "source": [
        "# Define the weight of the GAN loss\n",
        "gan_loss_weight = 1\n",
        "\n",
        "# Define the regularization parameter for the generator's L2 loss\n",
        "l2_lambda = 150\n",
        "\n",
        "# Define the loss function for the discriminator\n",
        "# Binary Cross Entropy is used as the loss function since we are dealing with a binary classification problem (real vs fake images)\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    \"\"\"\n",
        "    This function calculates the total loss for the discriminator.\n",
        "\n",
        "    Parameters:\n",
        "    disc_real_output (Tensor): The discriminator's prediction on the real images\n",
        "    disc_generated_output (Tensor): The discriminator's prediction on the generated (fake) images\n",
        "\n",
        "    Returns:\n",
        "    total_disc_loss (Tensor): The total loss for the discriminator\n",
        "    \"\"\"\n",
        "\n",
        "    # Cross entropy loss for real images (label 1 = real)\n",
        "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "    # Cross entropy loss for generated (fake) images (label 0 = fake)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    # Total loss for the discriminator\n",
        "    total_disc_loss = real_loss + fake_loss\n",
        "\n",
        "    return total_disc_loss\n",
        "\n",
        "\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "    \"\"\"\n",
        "    This function calculates the total loss for the generator.\n",
        "\n",
        "    Parameters:\n",
        "    disc_generated_output (Tensor): The discriminator's prediction on the generated (fake) images\n",
        "    gen_output (Tensor): The generated (fake) images\n",
        "    target (Tensor): The real images\n",
        "\n",
        "    Returns:\n",
        "    total_gen_loss (Tensor): The total loss for the generator\n",
        "    gan_loss (Tensor): The GAN loss for the generator\n",
        "    l2_loss (Tensor): The L2 loss for the generator\n",
        "    \"\"\"\n",
        "\n",
        "    # GAN loss (objective: engañar al discriminador para que piense que la imagen generada es real)\n",
        "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    # L2 Loss (Mean Squared Error entre la imagen generada y la imagen real)\n",
        "    l2_loss = tf.reduce_mean(tf.square(target - gen_output))\n",
        "\n",
        "    # Total Generator Loss (GAN loss ponderada + L2 regularización)\n",
        "    total_gen_loss = gan_loss_weight * gan_loss + l2_lambda * l2_loss\n",
        "\n",
        "    return total_gen_loss, gan_loss, l2_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4voKtW8nWerj"
      },
      "source": [
        "## Build Generator and Discriminator Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yAG9-VRSWerj",
        "outputId": "a443875c-2fb9-4282-adeb-eca66371d644"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">578</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m295,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m73,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ up_sampling2d_2 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │          \u001b[38;5;34m18,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │             \u001b[38;5;34m578\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">760,226</span> (2.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m760,226\u001b[0m (2.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">758,882</span> (2.89 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m758,882\u001b[0m (2.89 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m1,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m524,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m513\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">899,137</span> (3.43 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m899,137\u001b[0m (3.43 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">897,345</span> (3.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m897,345\u001b[0m (3.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Instantiate the generator and discriminator models\n",
        "generator = build_generator_model()\n",
        "discriminator = build_discriminator_model()\n",
        "\n",
        "# Print out the model summaries\n",
        "generator.summary()\n",
        "discriminator.summary()\n",
        "\n",
        "# Define the optimizers for the generator and discriminator\n",
        "# Adam optimizer is used with a learning rate of 2e-4 and beta_1 (the exponential decay rate for the first moment estimates) of 0.5\n",
        "# It is recommended to experiment with different values for the learning rate. Beta_1 value of 0.5 is recommended for GANs\n",
        "# It is possible that the optimal learning rate for the generator and discriminator is different from each other\n",
        "gen_learning_rate = 2e-4\n",
        "gene_beta_1 = 0.5\n",
        "\n",
        "disc_learning_rate = 2e-4\n",
        "disc_beta_1 = 0.5\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(gen_learning_rate, beta_1=gene_beta_1)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(disc_learning_rate, beta_1=disc_beta_1)\n",
        "\n",
        "# Define the directory for storing the training checkpoints\n",
        "checkpoint_dir = os.path.join(WORKDIR, 'training-checkpoints')\n",
        "# Define the prefix for the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# Create a checkpoint object which will be used to save and load the models and optimizers\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "# Create a manager for the checkpoint object, which will be responsible for saving and loading the checkpoints\n",
        "# max_to_keep parameter is set to 3, meaning that only the 3 most recent checkpoints will be kept\n",
        "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y18gcQglWerj"
      },
      "outputs": [],
      "source": [
        "# Define the directory and file for storing the TensorBoard summary logs\n",
        "summary_log_file = os.path.join(\n",
        "    WORKDIR, 'tf-summary', datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# Create a summary writer for writing the summary logs\n",
        "summary_writer = tf.summary.create_file_writer(summary_log_file)\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_image, target, epoch):\n",
        "    \"\"\"\n",
        "    This function performs one training step for the generator and discriminator.\n",
        "\n",
        "    Parameters:\n",
        "    input_image (Tensor): The input image\n",
        "    target (Tensor): The target image\n",
        "    epoch (int): The current epoch number\n",
        "\n",
        "    Returns:\n",
        "    gen_total_loss (Tensor): The total loss for the generator\n",
        "    disc_loss (Tensor): The loss for the discriminator\n",
        "    \"\"\"\n",
        "\n",
        "    # Open a GradientTape context for automatic differentiation\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        gen_total_loss = 0  # Initialize the total loss for the generator\n",
        "        gen_gan_loss = 0  # Initialize the GAN loss for the generator\n",
        "        gen_l2_loss = 0  # Initialize the L2 loss for the generator\n",
        "        disc_loss = 0  # Initialize the loss for the discriminator\n",
        "\n",
        "        # Generate an image using the generator\n",
        "        # (remember to set training=True, since during training time BatchNormalization layers are applied using the batch mean and variance)\n",
        "        gen_output = generator(input_image, training=True)\n",
        "\n",
        "        # Get the discriminator's predictions on the real and generated images\n",
        "        # (remember to set training=True, since during training time BatchNormalization layers are applied using the batch mean and variance)\n",
        "        disc_real_output = discriminator(target, training=True)\n",
        "        disc_generated_output = discriminator(gen_output, training=True)\n",
        "\n",
        "        # Calculate the losses for the generator and discriminator\n",
        "        gen_total_loss, gen_gan_loss, gen_l2_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    # Calculate the gradients of the generator's and discriminator's losses with respect to the trainable variables of each model\n",
        "    # Use the gradient() method of the GradientTape object of each model to calculate the gradients of the losses with respect to the trainable variables of the corresponding model\n",
        "    gen_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
        "    disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Apply the gradients to the model's trainable variables\n",
        "    # Use the apply_gradients() method of the optimizer object to apply the gradients\n",
        "    # The apply_gradients() method takes a list of (gradient, variable) pairs\n",
        "    # zip() function can be used to iterate over two lists simultaneously (i.e., the gradients and the model's trainable variables)\n",
        "    generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
        "\n",
        "    # Write the losses to the summary logs\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "        tf.summary.scalar('gen_l2_loss', gen_l2_loss, step=epoch)\n",
        "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
        "\n",
        "    return gen_total_loss, disc_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIsf75niWerj",
        "outputId": "41ef272d-3384-43a6-c82f-063c17ae3436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing from scratch\n"
          ]
        }
      ],
      "source": [
        "# The checkpoint manager will load the latest checkpoint if it exists\n",
        "# This will be used to resume training if the training process was interrupted\n",
        "# If no checkpoint exists, the models will be initialized from scratch\n",
        "\n",
        "# Restore the latest checkpoint using the checkpoint manager\n",
        "checkpoint.restore(manager.latest_checkpoint)\n",
        "\n",
        "# If a checkpoint was found and restored, print a message indicating the checkpoint file\n",
        "if manager.latest_checkpoint:\n",
        "    print('Restored from {}'.format(manager.latest_checkpoint))\n",
        "\n",
        "# If no checkpoint was found, print a message indicating that the models are being initialized from scratch\n",
        "else:\n",
        "    print('Initializing from scratch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlyJXbxzWerj",
        "outputId": "03d78318-d5ce-4262-cfd0-4c9ccdc943f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:780: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n",
            "  0%|          | 1/200 [00:39<2:09:30, 39.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: gen loss: 3.7049975395202637, disc loss: 1.6393542289733887, time: 39.04s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/200 [01:09<1:52:01, 33.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: gen loss: 2.458028554916382, disc loss: 1.50822114944458, time: 30.35s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/200 [01:38<1:44:17, 31.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: gen loss: 2.3558623790740967, disc loss: 1.4559720754623413, time: 29.16s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/200 [02:09<1:42:56, 31.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: gen loss: 2.2841339111328125, disc loss: 1.4275315999984741, time: 31.12s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 5/200 [02:39<1:40:51, 31.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: gen loss: 2.2325351238250732, disc loss: 1.4124574661254883, time: 30.18s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 6/200 [03:10<1:39:51, 30.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: gen loss: 2.2036514282226562, disc loss: 1.3982446193695068, time: 30.60s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 7/200 [03:40<1:38:15, 30.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: gen loss: 2.181772232055664, disc loss: 1.3944933414459229, time: 29.85s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 8/200 [04:10<1:37:49, 30.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: gen loss: 2.1679811477661133, disc loss: 1.3899670839309692, time: 30.62s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 9/200 [04:40<1:36:44, 30.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: gen loss: 2.159566879272461, disc loss: 1.3889145851135254, time: 29.99s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 10/200 [05:11<1:36:44, 30.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: gen loss: 2.1507558822631836, disc loss: 1.3883802890777588, time: 30.67s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 11/200 [05:41<1:35:29, 30.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: gen loss: 2.1426913738250732, disc loss: 1.3876473903656006, time: 29.77s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 12/200 [06:12<1:35:15, 30.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: gen loss: 2.1354644298553467, disc loss: 1.3873909711837769, time: 30.59s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 13/200 [06:41<1:33:57, 30.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: gen loss: 2.128920316696167, disc loss: 1.387600302696228, time: 29.57s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 14/200 [07:13<1:34:50, 30.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: gen loss: 2.1214559078216553, disc loss: 1.3876855373382568, time: 31.62s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 15/200 [07:43<1:33:56, 30.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: gen loss: 2.114452362060547, disc loss: 1.387860655784607, time: 30.18s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 16/200 [08:13<1:33:12, 30.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: gen loss: 2.110053300857544, disc loss: 1.3876681327819824, time: 30.22s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 17/200 [08:43<1:32:06, 30.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: gen loss: 2.1050384044647217, disc loss: 1.3872246742248535, time: 29.74s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 18/200 [09:14<1:31:53, 30.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: gen loss: 2.0969276428222656, disc loss: 1.3876535892486572, time: 30.49s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|▉         | 19/200 [09:55<1:41:02, 33.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: gen loss: 2.091463804244995, disc loss: 1.3873876333236694, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 20/200 [10:25<1:38:04, 32.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: gen loss: 2.08453369140625, disc loss: 1.3875373601913452, time: 30.62s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 21/200 [10:56<1:35:15, 31.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: gen loss: 2.0793697834014893, disc loss: 1.3880473375320435, time: 30.15s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 22/200 [11:26<1:33:17, 31.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: gen loss: 2.076314926147461, disc loss: 1.3875656127929688, time: 30.32s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 23/200 [12:07<1:41:10, 34.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: gen loss: 2.068007707595825, disc loss: 1.3875757455825806, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 24/200 [12:37<1:37:02, 33.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: gen loss: 2.065131902694702, disc loss: 1.387483835220337, time: 30.26s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 25/200 [13:07<1:33:36, 32.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: gen loss: 2.0585598945617676, disc loss: 1.387560486793518, time: 29.79s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 26/200 [13:38<1:32:29, 31.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: gen loss: 2.0513556003570557, disc loss: 1.3874738216400146, time: 31.42s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▎        | 27/200 [14:08<1:30:23, 31.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: gen loss: 2.044816255569458, disc loss: 1.38800048828125, time: 30.08s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 28/200 [14:38<1:28:44, 30.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: gen loss: 2.03851056098938, disc loss: 1.3872010707855225, time: 30.03s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 29/200 [15:08<1:27:15, 30.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: gen loss: 2.03244948387146, disc loss: 1.3875691890716553, time: 29.81s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 30/200 [15:39<1:26:32, 30.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: gen loss: 2.0250394344329834, disc loss: 1.3873522281646729, time: 30.20s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 31/200 [16:09<1:26:18, 30.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: gen loss: 2.0183939933776855, disc loss: 1.3877674341201782, time: 30.86s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 32/200 [16:50<1:34:27, 33.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: gen loss: 2.012284517288208, disc loss: 1.3876967430114746, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 33/200 [17:21<1:31:09, 32.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: gen loss: 2.0057613849639893, disc loss: 1.3876954317092896, time: 30.45s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 34/200 [17:52<1:29:27, 32.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: gen loss: 1.9959646463394165, disc loss: 1.3874255418777466, time: 31.37s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 35/200 [18:23<1:27:45, 31.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: gen loss: 1.9894241094589233, disc loss: 1.3873921632766724, time: 30.93s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 36/200 [18:53<1:25:26, 31.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: gen loss: 1.9802865982055664, disc loss: 1.387590765953064, time: 29.73s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 37/200 [19:23<1:24:02, 30.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: gen loss: 1.972350001335144, disc loss: 1.3874502182006836, time: 30.17s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 38/200 [19:53<1:22:31, 30.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: gen loss: 1.965073585510254, disc loss: 1.3872888088226318, time: 29.69s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 39/200 [20:24<1:22:12, 30.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: gen loss: 1.9559813737869263, disc loss: 1.3875027894973755, time: 30.81s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 40/200 [20:54<1:21:16, 30.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: gen loss: 1.9484177827835083, disc loss: 1.387494683265686, time: 29.82s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 41/200 [21:24<1:20:33, 30.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: gen loss: 1.9391851425170898, disc loss: 1.3876245021820068, time: 30.20s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 42/200 [21:54<1:19:53, 30.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: gen loss: 1.9316980838775635, disc loss: 1.3872089385986328, time: 30.19s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 43/200 [22:24<1:19:04, 30.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: gen loss: 1.9200798273086548, disc loss: 1.3877453804016113, time: 29.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 44/200 [22:54<1:18:43, 30.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: gen loss: 1.913784384727478, disc loss: 1.3871605396270752, time: 30.42s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▎       | 45/200 [23:26<1:19:13, 30.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: gen loss: 1.903648853302002, disc loss: 1.3877638578414917, time: 31.58s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 46/200 [23:57<1:18:42, 30.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: gen loss: 1.898617148399353, disc loss: 1.3875526189804077, time: 30.63s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 47/200 [24:26<1:17:30, 30.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: gen loss: 1.889061689376831, disc loss: 1.3871514797210693, time: 29.77s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 48/200 [24:57<1:16:59, 30.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: gen loss: 1.8825485706329346, disc loss: 1.387601375579834, time: 30.36s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 49/200 [25:27<1:16:05, 30.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: gen loss: 1.8733025789260864, disc loss: 1.387821078300476, time: 29.86s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 50/200 [25:58<1:16:05, 30.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: gen loss: 1.864298701286316, disc loss: 1.3875151872634888, time: 30.73s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 51/200 [26:27<1:15:07, 30.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51: gen loss: 1.8553065061569214, disc loss: 1.3873761892318726, time: 29.81s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 52/200 [26:58<1:14:35, 30.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52: gen loss: 1.8480098247528076, disc loss: 1.3876792192459106, time: 30.22s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 53/200 [27:39<1:21:57, 33.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53: gen loss: 1.8400933742523193, disc loss: 1.3873746395111084, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 54/200 [28:09<1:19:14, 32.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54: gen loss: 1.8328487873077393, disc loss: 1.3872464895248413, time: 30.49s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 55/200 [28:39<1:17:01, 31.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55: gen loss: 1.8259116411209106, disc loss: 1.387290596961975, time: 30.25s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 56/200 [29:09<1:14:57, 31.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56: gen loss: 1.8183481693267822, disc loss: 1.3874889612197876, time: 29.74s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 57/200 [29:50<1:21:23, 34.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57: gen loss: 1.809476375579834, disc loss: 1.3874295949935913, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 58/200 [30:22<1:19:29, 33.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58: gen loss: 1.8019359111785889, disc loss: 1.3874928951263428, time: 32.29s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 59/200 [30:53<1:16:42, 32.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59: gen loss: 1.7946065664291382, disc loss: 1.387264370918274, time: 30.42s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 60/200 [31:22<1:14:06, 31.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60: gen loss: 1.7893143892288208, disc loss: 1.387341856956482, time: 29.51s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 61/200 [31:53<1:12:43, 31.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61: gen loss: 1.7809807062149048, disc loss: 1.3877849578857422, time: 30.50s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 62/200 [32:23<1:11:21, 31.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62: gen loss: 1.7747136354446411, disc loss: 1.387382984161377, time: 30.17s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 63/200 [32:53<1:10:18, 30.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63: gen loss: 1.7656737565994263, disc loss: 1.3873337507247925, time: 30.25s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 64/200 [33:24<1:09:20, 30.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64: gen loss: 1.7579622268676758, disc loss: 1.387423038482666, time: 30.13s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▎      | 65/200 [33:54<1:08:32, 30.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65: gen loss: 1.754616141319275, disc loss: 1.3869895935058594, time: 30.16s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 66/200 [34:24<1:07:50, 30.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66: gen loss: 1.7456787824630737, disc loss: 1.3874919414520264, time: 30.16s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▎      | 67/200 [34:54<1:07:17, 30.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67: gen loss: 1.7410191297531128, disc loss: 1.387588381767273, time: 30.32s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 68/200 [35:35<1:13:46, 33.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68: gen loss: 1.7322431802749634, disc loss: 1.3874537944793701, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 69/200 [36:05<1:10:55, 32.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69: gen loss: 1.7275174856185913, disc loss: 1.3875343799591064, time: 30.02s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 70/200 [36:36<1:09:17, 31.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70: gen loss: 1.7230799198150635, disc loss: 1.3872079849243164, time: 30.55s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 71/200 [37:06<1:07:26, 31.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71: gen loss: 1.7164891958236694, disc loss: 1.3872785568237305, time: 29.93s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 72/200 [37:36<1:06:17, 31.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72: gen loss: 1.712570309638977, disc loss: 1.38730788230896, time: 30.38s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 73/200 [38:06<1:04:47, 30.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73: gen loss: 1.702734112739563, disc loss: 1.3874722719192505, time: 29.54s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 74/200 [38:39<1:05:43, 31.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74: gen loss: 1.7007900476455688, disc loss: 1.3873214721679688, time: 32.89s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 75/200 [39:09<1:04:29, 30.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75: gen loss: 1.693427562713623, disc loss: 1.3873372077941895, time: 30.16s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 76/200 [39:39<1:03:33, 30.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76: gen loss: 1.6850945949554443, disc loss: 1.3875353336334229, time: 30.27s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 77/200 [40:09<1:02:29, 30.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77: gen loss: 1.682045340538025, disc loss: 1.3876080513000488, time: 29.85s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 78/200 [40:39<1:01:52, 30.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78: gen loss: 1.6805349588394165, disc loss: 1.3872801065444946, time: 30.31s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 79/200 [41:20<1:07:44, 33.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79: gen loss: 1.6747374534606934, disc loss: 1.3873651027679443, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 80/200 [41:51<1:05:21, 32.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80: gen loss: 1.6662064790725708, disc loss: 1.3871358633041382, time: 30.37s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 81/200 [42:22<1:03:45, 32.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81: gen loss: 1.6623152494430542, disc loss: 1.3875720500946045, time: 30.89s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 82/200 [42:52<1:02:03, 31.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 82: gen loss: 1.6569325923919678, disc loss: 1.3874343633651733, time: 30.15s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 83/200 [43:22<1:00:56, 31.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 83: gen loss: 1.6503446102142334, disc loss: 1.3870989084243774, time: 30.54s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 84/200 [43:52<59:39, 30.85s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 84: gen loss: 1.6485432386398315, disc loss: 1.38784658908844, time: 29.93s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▎     | 85/200 [44:23<59:09, 30.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85: gen loss: 1.6405937671661377, disc loss: 1.3873679637908936, time: 30.90s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 86/200 [45:04<1:04:23, 33.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86: gen loss: 1.6350053548812866, disc loss: 1.3874417543411255, time: 40.95s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▎     | 87/200 [45:35<1:02:15, 33.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87: gen loss: 1.6346244812011719, disc loss: 1.387006163597107, time: 31.10s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 88/200 [46:06<1:00:07, 32.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 88: gen loss: 1.6293925046920776, disc loss: 1.3876484632492065, time: 30.23s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 89/200 [46:37<59:01, 31.91s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89: gen loss: 1.6220396757125854, disc loss: 1.3874485492706299, time: 31.18s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 90/200 [47:08<57:57, 31.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90: gen loss: 1.6204862594604492, disc loss: 1.3874502182006836, time: 30.64s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 91/200 [47:38<56:35, 31.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 91: gen loss: 1.617641568183899, disc loss: 1.3873310089111328, time: 30.08s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 92/200 [48:19<1:01:21, 34.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92: gen loss: 1.6139642000198364, disc loss: 1.3873534202575684, time: 40.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 93/200 [48:50<59:02, 33.11s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 93: gen loss: 1.608139157295227, disc loss: 1.3876116275787354, time: 30.81s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 94/200 [49:24<59:04, 33.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 94: gen loss: 1.6051746606826782, disc loss: 1.387412190437317, time: 34.22s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 95/200 [49:54<57:01, 32.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 95: gen loss: 1.600922703742981, disc loss: 1.3874377012252808, time: 30.58s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 96/200 [50:24<55:12, 31.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 96: gen loss: 1.593453288078308, disc loss: 1.3871852159500122, time: 30.13s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 97/200 [50:54<53:41, 31.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 97: gen loss: 1.5954186916351318, disc loss: 1.387518286705017, time: 29.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 98/200 [51:25<52:42, 31.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 98: gen loss: 1.5847903490066528, disc loss: 1.3873754739761353, time: 30.38s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|████▉     | 99/200 [51:56<52:03, 30.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99: gen loss: 1.585731863975525, disc loss: 1.387172818183899, time: 30.73s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 100/200 [52:26<51:15, 30.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100: gen loss: 1.5805468559265137, disc loss: 1.3873276710510254, time: 30.04s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 101/200 [52:57<50:47, 30.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 101: gen loss: 1.5788631439208984, disc loss: 1.387142539024353, time: 30.84s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 102/200 [53:27<49:47, 30.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 102: gen loss: 1.5721873044967651, disc loss: 1.3872731924057007, time: 29.79s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 103/200 [53:58<49:32, 30.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 103: gen loss: 1.5721672773361206, disc loss: 1.387092113494873, time: 31.01s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 104/200 [54:28<48:43, 30.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 104: gen loss: 1.5669864416122437, disc loss: 1.3871904611587524, time: 29.99s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▎    | 105/200 [54:59<48:45, 30.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 105: gen loss: 1.5642163753509521, disc loss: 1.3875176906585693, time: 31.58s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 106/200 [55:31<48:31, 30.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 106: gen loss: 1.5586557388305664, disc loss: 1.3875035047531128, time: 31.35s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 107/200 [56:01<47:43, 30.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 107: gen loss: 1.5545865297317505, disc loss: 1.3871517181396484, time: 30.36s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 108/200 [56:32<47:21, 30.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 108: gen loss: 1.5535862445831299, disc loss: 1.3874001502990723, time: 31.11s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 109/200 [57:02<46:25, 30.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 109: gen loss: 1.5497699975967407, disc loss: 1.38729989528656, time: 29.97s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 110/200 [57:33<46:03, 30.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 110: gen loss: 1.544152021408081, disc loss: 1.3874722719192505, time: 30.54s\n"
          ]
        }
      ],
      "source": [
        "# Loop over the epochs\n",
        "for e in tqdm(range(EPOCHS)):\n",
        "    # Record the start time of the epoch\n",
        "    start_time = time()\n",
        "\n",
        "    gen_loss_total = 0  # Initialize the total loss for the generator\n",
        "    disc_loss_total = 0  # Initialize the total loss for the discriminator\n",
        "\n",
        "    # Loop over the training dataset\n",
        "    for input_image, target in train_dataset:\n",
        "        # Perform one training step and get the generator and discriminator losses\n",
        "        gen_loss, disc_loss = train_step(input_image, target, e)\n",
        "\n",
        "        # Add the losses to the total losses\n",
        "        gen_loss_total += gen_loss\n",
        "        disc_loss_total += disc_loss\n",
        "\n",
        "    # Calculate the time taken for the epoch\n",
        "    time_taken = time() - start_time\n",
        "\n",
        "    # If the epoch number is a multiple of 10, save a checkpoint\n",
        "    if (e + 1) % 10 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    # Print the epoch number, average generator loss, average discriminator loss, and time taken\n",
        "    print(f'Epoch {e + 1}: gen loss: {gen_loss_total / len(train_dataset)}, '\n",
        "          f'disc loss: {disc_loss_total / len(train_dataset)}, time: {time_taken:.2f}s')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCCiXDhaWerk"
      },
      "source": [
        "## Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAVzuXnKWerk"
      },
      "outputs": [],
      "source": [
        "# Define the number of samples to generate\n",
        "n_samples = 150\n",
        "# Generate colorized versions of the first n_samples grayscale images in the test set\n",
        "Y_hat = generator(X_test[:n_samples])\n",
        "\n",
        "# Define the number of rows in the grid, which is equal to the number of samples\n",
        "num_rows = len(Y_hat)\n",
        "\n",
        "# Define the number of columns in the grid and the size of each image\n",
        "num_cols = 3  # Number of columns in the grid\n",
        "img_size = 1  # Size of each image in the grid\n",
        "\n",
        "# Create a grid of subplots with num_rows rows and num_cols columns\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * img_size, num_rows * img_size))\n",
        "fig.subplots_adjust(hspace=0.3, wspace=0.1)  # Adjust spacing between subplots\n",
        "\n",
        "# Loop over the grayscale images, original color images, and colorized images\n",
        "for row, (x, y, y_hat) in enumerate(zip(X_test[:n_samples], Y_test[:n_samples], Y_hat)):\n",
        "\n",
        "    # Convert the original color image from Lab to RGB\n",
        "    orig_lab = np.dstack((x, y * 128))\n",
        "    orig_rgb = lab2rgb(orig_lab)\n",
        "\n",
        "    # Convert the grayscale image from Lab to RGB\n",
        "    grayscale_lab = np.dstack((x, np.zeros((IMAGE_SIZE, IMAGE_SIZE, 2))))\n",
        "    grayscale_rgb = lab2rgb(grayscale_lab)\n",
        "\n",
        "    # Convert the colorized image from Lab to RGB\n",
        "    predicted_lab = np.dstack((x, y_hat * 128))\n",
        "    predicted_rgb = lab2rgb(predicted_lab)\n",
        "\n",
        "    # Display the grayscale image in the first column of the current row\n",
        "    ax = axes[row, 0]  # Get the appropriate axis for the current subplot\n",
        "    ax.axis('off')  # Turn off axis labels\n",
        "    ax.imshow(grayscale_rgb)\n",
        "    ax.set_title('Grayscale')\n",
        "\n",
        "    # Display the original color image in the second column of the current row\n",
        "    ax = axes[row, 1]  # Move to the next column for original RGB\n",
        "    ax.axis('off')\n",
        "    ax.imshow(orig_rgb)\n",
        "    ax.set_title('Original')\n",
        "\n",
        "    # Display the colorized image in the third column of the current row\n",
        "    ax = axes[row, 2]  # Move to the next column for predicted colorized image\n",
        "    ax.axis('off')\n",
        "    ax.imshow(predicted_rgb)\n",
        "    ax.set_title('Predicted')\n",
        "\n",
        "    # Print the current row number to the console\n",
        "    sys.stdout.flush()\n",
        "    sys.stdout.write('\\r{} / {}'.format(row + 1, num_rows))\n",
        "\n",
        "# Hide empty subplots if any\n",
        "for ax_row in axes:\n",
        "    for ax in ax_row:\n",
        "        if not ax.has_data():\n",
        "            ax.axis('off')\n",
        "\n",
        "# Adjust the padding between subplots\n",
        "plt.tight_layout(pad=0.5)\n",
        "# Save the figure as an image file\n",
        "plt.savefig(os.path.join(WORKDIR, 'results', 'image_grid.png'))\n",
        "# Display the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KsTOhdRWerk"
      },
      "source": [
        "## Save the Generator and Discriminator Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpdJvNZ4Werk"
      },
      "outputs": [],
      "source": [
        "# Save the checkpoints of the models and optimizers so that they can be loaded later\n",
        "# Save the generator model in the SavedModel format\n",
        "tf.saved_model.save(generator, os.path.join(WORKDIR, \"generator-saved-model\"))\n",
        "\n",
        "# Save the discriminator model in the SavedModel format\n",
        "tf.saved_model.save(discriminator, os.path.join(WORKDIR, \"disciminator-saved-model\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
